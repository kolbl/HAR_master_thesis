{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91688\n169\n1830\n1593995\n9262\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import bootstrap_plot\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "seconds = \"5s\"\n",
    "\n",
    "path = \"./src/Data/Training\"\n",
    "\n",
    "all_files = []\n",
    "for root,d_names,f_names in os.walk(path):\n",
    "    for f in f_names:\n",
    "        all_files.append(os.path.join(root, f))\n",
    "#print(\"all files = %s\" %all_files)\n",
    "\n",
    "def getDFForDataSource(data_source):\n",
    "    file_list_a = []\n",
    "    for f in all_files:\n",
    "        if \"A-\" + data_source + \".csv\" in f:\n",
    "            file_list_a.append(f)\n",
    "    df_a = pd.concat([pd.read_csv(f,  delimiter=\";\") for f in file_list_a ], sort=True)\n",
    "    file_list_b = []\n",
    "    for f in all_files:\n",
    "        if \"B-\" + data_source + \".csv\" in f:\n",
    "            file_list_b.append(f)\n",
    "    df_b = pd.concat([pd.read_csv(f,  delimiter=\";\") for f in file_list_b ], sort=True)\n",
    "    file_list_c = []\n",
    "    for f in all_files:\n",
    "        if \"C-\" + data_source + \".csv\" in f:\n",
    "            file_list_c.append(f)\n",
    "    df_c = pd.concat([pd.read_csv(f,  delimiter=\";\") for f in file_list_c ], sort=True)\n",
    "    df_a[\"segment\"] = \"A\"\n",
    "    df_b[\"segment\"] = \"B\"\n",
    "    df_c[\"segment\"] = \"C\"\n",
    "    return pd.concat([df_a, df_b, df_c], sort=True)\n",
    "\n",
    "\n",
    "# get data frame for each data source from CSV files\n",
    "proximity_df = getDFForDataSource(\"proximity\")\n",
    "sensors_df = getDFForDataSource(\"sensors\")\n",
    "activities_df = getDFForDataSource(\"activity\")\n",
    "acceleration_df = getDFForDataSource(\"acceleration\")\n",
    "floor_df = getDFForDataSource(\"floor\")\n",
    "\n",
    "activities_df[\"begin\"] = pd.to_datetime(activities_df[\"DATE BEGIN\"])\n",
    "activities_df[\"end\"] = pd.to_datetime(activities_df[\"DATE END\"])\n",
    "activities_df.drop([\"DATE BEGIN\"], axis=1, inplace=True)\n",
    "activities_df.drop([\"DATE END\"], axis=1, inplace=True)\n",
    "activities_df[\"duration\"] = activities_df[\"end\"] - activities_df[\"begin\"]\n",
    "activities = pd.read_csv(\"./src/activities.csv\", delimiter=\",\")\n",
    "activities_df = pd.merge(activities_df, activities, on=\"ACTIVITY\")\n",
    "\n",
    "# total of samples\n",
    "print(len(floor_df))\n",
    "print(len(activities_df))\n",
    "print(len(sensors_df))\n",
    "print(len(acceleration_df))\n",
    "print(len(proximity_df))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            TIMESTAMP activity segment activity name\n0 2017-11-15 12:24:14    Act24       A       Wake up\n0 2017-11-15 12:24:15    Act24       A       Wake up\n0 2017-11-15 12:24:16    Act24       A       Wake up\n0 2017-11-15 12:24:17    Act24       A       Wake up\n0 2017-11-15 12:24:18    Act24       A       Wake up\n"
     ]
    }
   ],
   "source": [
    "# convert activity data into 1 sec slots\n",
    "\n",
    "activities_df_resampled = pd.DataFrame(columns=[\"TIMESTAMP\", \"activity\", \"segment\", \"activity name\"])\n",
    "\n",
    "for index, row in activities_df.iterrows():\n",
    "    duration_in_sec = row[\"duration\"].total_seconds() \n",
    "    for s in range(int(duration_in_sec)):\n",
    "\n",
    "        new_row = pd.DataFrame({\"TIMESTAMP\": [row[\"begin\"] + datetime.timedelta(0,s)], \n",
    "                                \"activity\": [row[\"ACTIVITY\"]],\n",
    "                                \"segment\": [row[\"segment\"]],\n",
    "                                \"activity name\": [row[\"Activity Name\"]]\n",
    "                                }) \n",
    "        activities_df_resampled = activities_df_resampled.append(new_row)\n",
    "\n",
    "        \n",
    "print(activities_df_resampled.head()) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare dfs to similar column format\n",
    "\n",
    "# proximity df\n",
    "proximity_df_resampled = proximity_df.copy()\n",
    "proximity_df_resampled.drop([\"ID\"], axis=1, inplace=True)\n",
    "proximity_objects = proximity_df_resampled[\"OBJECT\"].unique()\n",
    "proximity_df_resampled = pd.concat([proximity_df_resampled, pd.DataFrame(columns=proximity_objects)], ignore_index=True, sort=True)\n",
    "for index, row in proximity_df_resampled.iterrows():\n",
    "    object = row[\"OBJECT\"]\n",
    "    # https://www.speedguide.net/faq/how-does-rssi-dbm-relate-to-signal-quality-percent-439\n",
    "    if(row[\"RSSI\"] >= -97):\n",
    "        rssi = 1\n",
    "    else:\n",
    "        rssi = 0\n",
    "    proximity_df_resampled.loc[index, object] = rssi\n",
    "proximity_df_resampled.drop([\"OBJECT\"], axis=1, inplace=True)\n",
    "proximity_df_resampled.drop([\"RSSI\"], axis=1, inplace=True)\n",
    "proximity_df_resampled[\"TIMESTAMP\"] = pd.to_datetime(proximity_df_resampled[\"TIMESTAMP\"])\n",
    "\n",
    "\n",
    "# sensors df\n",
    "sensors_df_resampled = sensors_df.copy()\n",
    "sensors_df_resampled.drop([\"DATE\"], axis=1, inplace=True)\n",
    "sensors_df_resampled.drop([\"HABITANT\"], axis=1, inplace=True)\n",
    "sensors_objects = ['SM4', 'C14', 'D07', 'C10', 'C09', 'SM3', 'SM1', 'D04', 'D01', 'D10', 'D02', 'D03',\n",
    " 'C13', 'M01', 'C08', 'C12', 'D09', 'C04', 'C07', 'H01', 'D08', 'TV0', 'S09', 'SM5',\n",
    " 'C02', 'C01', 'D05', 'C05', 'C03', 'C015']\n",
    "sensors_df_resampled = pd.concat([sensors_df_resampled, pd.DataFrame(columns=sensors_objects)], ignore_index=True, sort=True)\n",
    "for index, row in sensors_df_resampled.iterrows():\n",
    "    object = row[\"OBJECT\"]\n",
    "    # preprocess the state column: \"open\", \"movement\" and \"pressure\" = 1, else 0\n",
    "    if row[\"STATE\"] == \"Movement\" or row[\"STATE\"] == \"Pressure\" or row[\"STATE\"] == \"Open\":\n",
    "        sensors_df_resampled.loc[index, object] = 1\n",
    "    else: \n",
    "        sensors_df_resampled.loc[index, object] = 0\n",
    "sensors_df_resampled.drop([\"OBJECT\"], axis=1, inplace=True)\n",
    "sensors_df_resampled.drop([\"STATE\"], axis=1, inplace=True)\n",
    "sensors_df_resampled[\"TIMESTAMP\"] = pd.to_datetime(sensors_df_resampled[\"TIMESTAMP\"])\n",
    "sensors_df_resampled.fillna(method='ffill', inplace=True)\n",
    "sensors_df_resampled = sensors_df_resampled.fillna(0)\n",
    "\n",
    "\n",
    "# acceleration df\n",
    "acceleration_df_resampled = acceleration_df.copy()\n",
    "acceleration_df_resampled[\"TIMESTAMP\"] = pd.to_datetime(acceleration_df_resampled[\"TIMESTAMP\"])\n",
    "\n",
    "\n",
    "# floor df\n",
    "floor_df_temp = floor_df[[\"TIMESTAMP\", \"DEVICE\"]].copy()\n",
    "# dropping duplicate values \n",
    "floor_df_temp.drop_duplicates(keep=False,inplace=True) \n",
    "# one hot encoding the nominal device data \n",
    "non_dummy_cols = ['TIMESTAMP']\n",
    "dummy_cols = list(set(floor_df_temp.columns) - set(non_dummy_cols))\n",
    "floor_df_resampled = pd.get_dummies(floor_df_temp, columns=dummy_cols, prefix=['floor'])\n",
    "\n",
    "\n",
    "proximity_df_resampled[\"TIMESTAMP\"] = pd.to_datetime(proximity_df_resampled[\"TIMESTAMP\"]).dt.floor('1s')\n",
    "sensors_df_resampled[\"TIMESTAMP\"] = pd.to_datetime(sensors_df_resampled[\"TIMESTAMP\"]).dt.floor('1s')\n",
    "acceleration_df_resampled[\"TIMESTAMP\"] = pd.to_datetime(acceleration_df_resampled[\"TIMESTAMP\"]).dt.floor('1s')\n",
    "floor_df_resampled[\"TIMESTAMP\"] = pd.to_datetime(floor_df_resampled[\"TIMESTAMP\"]).dt.floor('1s')\n",
    "\n",
    "proximity_df_resampled.drop([\"segment\"], axis=1, inplace=True)\n",
    "sensors_df_resampled.drop([\"segment\"], axis=1, inplace=True)\n",
    "acceleration_df_resampled.drop([\"segment\"], axis=1, inplace=True)\n",
    "\n",
    "proximity_df_resampled = proximity_df_resampled.set_index(\"TIMESTAMP\")\n",
    "sensors_df_resampled = sensors_df_resampled.set_index(\"TIMESTAMP\")\n",
    "acceleration_df_resampled = acceleration_df_resampled.set_index(\"TIMESTAMP\")\n",
    "floor_df_resampled = floor_df_resampled.set_index(\"TIMESTAMP\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4348\n1343\n6012\n3718\n"
     ]
    }
   ],
   "source": [
    "# convert sensor data into n sec slots, calculate mean if there are multiple entries for the same sensor data in the same time slot\n",
    "# input: df with columns timestamp, segment, columns for each feature\n",
    "\n",
    "\n",
    "proximity_df_resampled = proximity_df_resampled.fillna(0).astype(float)\n",
    "sensors_df_resampled = sensors_df_resampled.fillna(0.0).astype(float)\n",
    "acceleration_df_resampled = acceleration_df_resampled.astype(float)\n",
    "\n",
    "# resample in seconds\n",
    "# time-based overlapping sliding window technique with n sec overlap\n",
    "# see doc: https://pandas.pydata.org/pandas-docs/stable/user_guide/computation.html\n",
    "# for binary and proximity data: max\n",
    "# mean for rest\n",
    "\n",
    "proximity_df_resampled_in_sec = proximity_df_resampled.resample(seconds).max()\n",
    "sensors_df_resampled_in_sec = sensors_df_resampled.resample(seconds).max()\n",
    "acceleration_df_resampled_in_sec = acceleration_df_resampled.resample(seconds).mean()\n",
    "floor_df_resampled_in_sec = floor_df_resampled.resample(seconds).max()\n",
    "\n",
    "\n",
    "# drop nans\n",
    "proximity_df_resampled_in_sec = proximity_df_resampled_in_sec.dropna(how='all')\n",
    "sensors_df_resampled_in_sec = sensors_df_resampled_in_sec.dropna(how='all')\n",
    "acceleration_df_resampled_in_sec = acceleration_df_resampled_in_sec.dropna(how='all')\n",
    "floor_df_resampled_in_sec = floor_df_resampled_in_sec.dropna(how='all')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(len(proximity_df_resampled_in_sec))\n",
    "print(len(sensors_df_resampled_in_sec))\n",
    "print(len(acceleration_df_resampled_in_sec))\n",
    "print(len(floor_df_resampled_in_sec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge floor data into areas to reduce features\n",
    "# areas: entrance room, living room, bedroom, kitchen\n",
    "\n",
    "room_mapping = {'floor_01,01': 'living room', \n",
    "                'floor_01,02': 'living room',  \n",
    "                'floor_01,03': 'living room',  \n",
    "                'floor_01,04': 'living room',\n",
    "                'floor_01,05': 'living room',\n",
    "                'floor_01,06': 'living room',\n",
    "                'floor_01,07': 'living room',\n",
    "                'floor_01,08': 'entrance',\n",
    "                'floor_01,09': 'entrance',\n",
    "                'floor_02,01': 'living room',\n",
    "                'floor_02,02': 'living room',\n",
    "                'floor_02,03': 'living room',\n",
    "                'floor_02,04': 'living room',\n",
    "                'floor_02,05': 'living room',\n",
    "                'floor_02,06': 'living room',\n",
    "                'floor_02,07': 'living room',\n",
    "                'floor_02,08': 'entrance',\n",
    "                'floor_02,09': 'entrance',\n",
    "                'floor_02,10': 'entrance',\n",
    "                'floor_03,01': 'bed room',\n",
    "                'floor_03,02': 'bed room',\n",
    "                'floor_03,03': 'bed room',\n",
    "                'floor_03,04': 'bed room',\n",
    "                'floor_03,05': 'bed room',\n",
    "                'floor_03,06': 'kitchen',\n",
    "                'floor_03,07': 'kitchen',\n",
    "                'floor_03,08': 'kitchen',\n",
    "                'floor_03,09': 'kitchen',\n",
    "                'floor_04,01': 'bed room',\n",
    "                'floor_04,02': 'bed room',\n",
    "                'floor_04,03': 'bed room',\n",
    "                'floor_04,04': 'bed room',\n",
    "                'floor_04,05': 'bed room',\n",
    "                'floor_04,06': 'kitchen',\n",
    "                'floor_04,07': 'kitchen',\n",
    "                'floor_04,08': 'kitchen',\n",
    "                'floor_04,09': 'kitchen',\n",
    "                'floor_05,06': 'kitchen',\n",
    "                'floor_05,07': 'kitchen'             \n",
    "                } \n",
    "room_df = floor_df_resampled_in_sec.groupby(room_mapping, axis = 1).max()\n",
    "#room = pd.DataFrame(columns=[\"TIMESTAMP\", \"entrance\", \"living room\", \"bedroom\", \"kitchen\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample result is: \n            TIMESTAMP  BATHROOM TAP  BED  BOOK  C01  C015  C02  C03  C04  C05  \\\n0 2017-10-31 11:08:55           0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n1 2017-10-31 11:09:10           0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n2 2017-10-31 11:09:30           0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n3 2017-10-31 11:09:40           0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n4 2017-10-31 11:09:50           0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0   \n\n    ...     floor_04,04  floor_04,05  floor_04,06  floor_04,07  floor_04,08  \\\n0   ...             0.0          0.0          0.0          0.0          0.0   \n1   ...             0.0          0.0          0.0          0.0          0.0   \n2   ...             0.0          0.0          0.0          0.0          0.0   \n3   ...             0.0          0.0          0.0          0.0          0.0   \n4   ...             0.0          0.0          0.0          0.0          0.0   \n\n   floor_04,09  floor_05,06  floor_05,07  activity  segment  \n0          0.0          0.0          0.0       0.0      0.0  \n1          0.0          0.0          0.0       0.0      0.0  \n2          0.0          0.0          0.0       0.0      0.0  \n3          0.0          0.0          0.0       0.0      0.0  \n4          0.0          0.0          0.0       0.0      0.0  \n\n[5 rows x 90 columns]\n6326\n          TIMESTAMP  BATHROOM TAP  BED  BOOK  C01  C015  C02  C03  C04  C05  \\\nactivity                                                                      \n0.0             964           964  964   964  964   964  964  964  964  964   \n1.0             138           138  138   138  138   138  138  138  138  138   \n2.0             280           280  280   280  280   280  280  280  280  280   \n3.0             585           585  585   585  585   585  585  585  585  585   \n4.0             334           334  334   334  334   334  334  334  334  334   \n5.0             365           365  365   365  365   365  365  365  365  365   \n6.0             460           460  460   460  460   460  460  460  460  460   \n7.0             492           492  492   492  492   492  492  492  492  492   \n8.0              69            69   69    69   69    69   69   69   69   69   \n9.0             510           510  510   510  510   510  510  510  510  510   \n10.0            133           133  133   133  133   133  133  133  133  133   \n11.0             81            81   81    81   81    81   81   81   81   81   \n12.0            210           210  210   210  210   210  210  210  210  210   \n13.0             69            69   69    69   69    69   69   69   69   69   \n14.0              8             8    8     8    8     8    8    8    8    8   \n15.0            267           267  267   267  267   267  267  267  267  267   \n16.0             74            74   74    74   74    74   74   74   74   74   \n17.0            347           347  347   347  347   347  347  347  347  347   \n18.0            105           105  105   105  105   105  105  105  105  105   \n19.0             17            17   17    17   17    17   17   17   17   17   \n20.0             68            68   68    68   68    68   68   68   68   68   \n21.0            197           197  197   197  197   197  197  197  197  197   \n22.0            303           303  303   303  303   303  303  303  303  303   \n23.0             72            72   72    72   72    72   72   72   72   72   \n24.0            178           178  178   178  178   178  178  178  178  178   \n\n           ...     floor_04,03  floor_04,04  floor_04,05  floor_04,06  \\\nactivity   ...                                                          \n0.0        ...             964          964          964          964   \n1.0        ...             138          138          138          138   \n2.0        ...             280          280          280          280   \n3.0        ...             585          585          585          585   \n4.0        ...             334          334          334          334   \n5.0        ...             365          365          365          365   \n6.0        ...             460          460          460          460   \n7.0        ...             492          492          492          492   \n8.0        ...              69           69           69           69   \n9.0        ...             510          510          510          510   \n10.0       ...             133          133          133          133   \n11.0       ...              81           81           81           81   \n12.0       ...             210          210          210          210   \n13.0       ...              69           69           69           69   \n14.0       ...               8            8            8            8   \n15.0       ...             267          267          267          267   \n16.0       ...              74           74           74           74   \n17.0       ...             347          347          347          347   \n18.0       ...             105          105          105          105   \n19.0       ...              17           17           17           17   \n20.0       ...              68           68           68           68   \n21.0       ...             197          197          197          197   \n22.0       ...             303          303          303          303   \n23.0       ...              72           72           72           72   \n24.0       ...             178          178          178          178   \n\n          floor_04,07  floor_04,08  floor_04,09  floor_05,06  floor_05,07  \\\nactivity                                                                    \n0.0               964          964          964          964          964   \n1.0               138          138          138          138          138   \n2.0               280          280          280          280          280   \n3.0               585          585          585          585          585   \n4.0               334          334          334          334          334   \n5.0               365          365          365          365          365   \n6.0               460          460          460          460          460   \n7.0               492          492          492          492          492   \n8.0                69           69           69           69           69   \n9.0               510          510          510          510          510   \n10.0              133          133          133          133          133   \n11.0               81           81           81           81           81   \n12.0              210          210          210          210          210   \n13.0               69           69           69           69           69   \n14.0                8            8            8            8            8   \n15.0              267          267          267          267          267   \n16.0               74           74           74           74           74   \n17.0              347          347          347          347          347   \n18.0              105          105          105          105          105   \n19.0               17           17           17           17           17   \n20.0               68           68           68           68           68   \n21.0              197          197          197          197          197   \n22.0              303          303          303          303          303   \n23.0               72           72           72           72           72   \n24.0              178          178          178          178          178   \n\n          segment  \nactivity           \n0.0           964  \n1.0           138  \n2.0           280  \n3.0           585  \n4.0           334  \n5.0           365  \n6.0           460  \n7.0           492  \n8.0            69  \n9.0           510  \n10.0          133  \n11.0           81  \n12.0          210  \n13.0           69  \n14.0            8  \n15.0          267  \n16.0           74  \n17.0          347  \n18.0          105  \n19.0           17  \n20.0           68  \n21.0          197  \n22.0          303  \n23.0           72  \n24.0          178  \n\n[25 rows x 89 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# merge sensor timeslots with 2 sec with columns for every sensor (= feature)\n",
    "# add sensor data from all 4 sources\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html#scaling-features-to-a-range\n",
    "\n",
    "\n",
    "\n",
    "# Pre-Processing of data\n",
    "\n",
    "# normalisation\n",
    "def normalise(df):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    column_names_to_not_normalize = [\"TIMESTAMP\"]\n",
    "    column_names_to_normalize = [x for x in list(df) if x not in column_names_to_not_normalize ]\n",
    "    x = df[column_names_to_normalize].values\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df.index)\n",
    "    df[column_names_to_normalize] = df_temp\n",
    "    return df\n",
    "\n",
    "\n",
    "# normalise features of proximity and acceleration (rescale between values of 0 and 1)\n",
    "#acceleration_df_resampled_in_sec = normalise(acceleration_df_resampled_in_sec)\n",
    "\n",
    "\n",
    "# remove all features that are either one or zero in more than 99% of the samples\n",
    "# Boolean features are Bernoulli random variables, and the variance of such variables is given by Var[X] = p(1 - p)\n",
    "def variance_threshold_selector(data, threshold=0.5):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(data)\n",
    "    return data[data.columns[selector.get_support(indices=True)]]\n",
    "#print(variance_threshold_selector(sensors_df_resampled_in_sec, threshold=(.99 * (1 - .99))))\n",
    "# sensors_df_resampled_in_sec = variance_threshold_selector(sensors_df_resampled_in_sec, threshold=(.99 * (1 - .99)))\n",
    "\n",
    "\n",
    "# TODO: add commonly used features for acceleration sensor data features: Mean, Variance, Skewness, and Kurtosis sklearn\n",
    "\n",
    "\n",
    "merged_sensor_data = proximity_df_resampled_in_sec.combine_first(acceleration_df_resampled_in_sec)\\\n",
    "    .combine_first(sensors_df_resampled_in_sec).combine_first(floor_df_resampled_in_sec)#.combine_first(room_df)\n",
    "\n",
    "\n",
    "\n",
    "activities_df_resampled[\"segment\"] = activities_df_resampled[\"segment\"].map({\"A\": 0, \"B\": 1, \"C\": 2})\n",
    "activity_map = {\"Act01\": 1, \"Act02\": 2, \"Act03\": 3, \"Act04\": 4, \"Act05\": 5, \"Act06\": 6, \"Act07\": 7, \n",
    "                \"Act08\": 8, \"Act09\": 9,  \"Act10\": 10, \"Act11\": 11, \"Act12\": 12, \"Act13\": 13, \n",
    "                \"Act14\": 14,  \"Act15\": 15, \"Act16\": 16, \"Act17\": 17, \"Act18\": 18, \"Act19\": 19, \n",
    "                \"Act20\": 20, \"Act21\": 21, \"Act22\": 22, \"Act23\": 23, \"Act24\": 24, \"no activity\": 0}\n",
    "activities_df_resampled[\"activity\"] = activities_df_resampled[\"activity\"].map(activity_map)\n",
    "activities_df_resampled.drop([\"activity name\"], axis=1, inplace=True) # delete repeated activity\n",
    "\n",
    "activities_df_resampled[\"TIMESTAMP\"] = pd.to_datetime(activities_df_resampled[\"TIMESTAMP\"])\n",
    "activities_df_resampled = activities_df_resampled.set_index([\"TIMESTAMP\"])\n",
    "activities_df_resampled = activities_df_resampled.resample(seconds).median()\n",
    "activities_df_resampled = activities_df_resampled.reset_index()\n",
    "\n",
    "samples_training = pd.merge(merged_sensor_data, activities_df_resampled, on=\"TIMESTAMP\", how='left')\n",
    "\n",
    "# deal with missing data for 1 sec slots:\n",
    "# add activity labels to days (\"Act02\" or \"no activity\") and segment\n",
    "# if nan, then \"no activity\"\n",
    "samples_training[\"activity\"] = samples_training[\"activity\"].fillna(0)\n",
    "# get segment for nans\n",
    "samples_training[\"segment\"].fillna(method='backfill', inplace=True)\n",
    "# filling acceleration data with median of column\n",
    "samples_training[\"X\"].fillna(method='ffill', inplace=True) # ffill: propagate last valid observation forward to next valid\n",
    "samples_training[\"Y\"].fillna(method='ffill', inplace=True)\n",
    "samples_training[\"Z\"].fillna(method='ffill', inplace=True)\n",
    "# filling missing proximity data and missing sensors data with 0\n",
    "samples_training.fillna(0.0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# normalisation\n",
    "def normalise_whole_df(df):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    column_names_to_not_normalize = [\"TIMESTAMP\", \"activity\"]\n",
    "    column_names_to_normalize = [x for x in list(df) if x not in column_names_to_not_normalize ]\n",
    "    x = df[column_names_to_normalize].values\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df.index)\n",
    "    df[column_names_to_normalize] = df_temp\n",
    "    return df\n",
    "\n",
    "\n",
    "# normalise features of segment and acceleration (rescale between values of 0 and 1)\n",
    "samples_training = normalise_whole_df(samples_training)\n",
    "\n",
    "print(\"Training sample result is: \")\n",
    "print(samples_training.head())\n",
    "print(len(samples_training))\n",
    "\n",
    "\n",
    "\n",
    "print(samples_training.groupby(\"activity\").count())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            TIMESTAMP  BATHROOM TAP  BED  BOOK  Medication Box Sensor  \\\n0 2017-10-31 11:08:55           0.0  0.0   0.0                    0.0   \n1 2017-10-31 11:09:10           0.0  0.0   0.0                    0.0   \n2 2017-10-31 11:09:30           0.0  0.0   0.0                    0.0   \n3 2017-10-31 11:09:40           0.0  0.0   0.0                    0.0   \n4 2017-10-31 11:09:50           0.0  0.0   0.0                    0.0   \n\n   Fruit Platter Sensor  Pots Sensor  Water Bottle Sensor  Trash Sensor  \\\n0                   0.0          0.0                  0.0           0.0   \n1                   0.0          0.0                  0.0           0.0   \n2                   0.0          0.0                  0.0           0.0   \n3                   0.0          0.0                  0.0           0.0   \n4                   0.0          0.0                  0.0           0.0   \n\n   Tap Sensor   ...     floor_04,04  floor_04,05  floor_04,06  floor_04,07  \\\n0         0.0   ...             0.0          0.0          0.0          0.0   \n1         0.0   ...             0.0          0.0          0.0          0.0   \n2         0.0   ...             0.0          0.0          0.0          0.0   \n3         0.0   ...             0.0          0.0          0.0          0.0   \n4         0.0   ...             0.0          0.0          0.0          0.0   \n\n   floor_04,08  floor_04,09  floor_05,06  floor_05,07  activity  segment  \n0          0.0          0.0          0.0          0.0       0.0      0.0  \n1          0.0          0.0          0.0          0.0       0.0      0.0  \n2          0.0          0.0          0.0          0.0       0.0      0.0  \n3          0.0          0.0          0.0          0.0       0.0      0.0  \n4          0.0          0.0          0.0          0.0       0.0      0.0  \n\n[5 rows x 85 columns]\nIndex(['TIMESTAMP', 'BATHROOM TAP', 'BED', 'BOOK', 'Medication Box Sensor',\n       'Fruit Platter Sensor', 'Pots Sensor', 'Water Bottle Sensor',\n       'Trash Sensor', 'Tap Sensor', 'Tank Sensor', 'Pyjamas drawer Sensor',\n       'Bed Sensor', 'Refrigerator Sensor', 'Microwave  Sensor',\n       'Wardrobe Sensor', 'Cupboard Cups Sensor', 'Dishwasher Sensor',\n       'Top WC Sensor', 'Closet Sensor', 'Washing Machine  Sensor',\n       'Pantry Sensor', 'ENTRANCE DOOR', 'FOOD CUPBOARD', 'FRIDGE',\n       'GARBAGE CAN', 'Kettle Sensor', 'LAUNDRY BASKET', 'Door Sensor',\n       'MEDICINE BOX', 'POT DRAWER', 'PYJAMAS DRAWER', 'Sofa Pressure Sensor',\n       'Motion Sensor Kitchen', 'Motion Sensor Bathroom',\n       'Motion Sensor Bedroom', 'Motion Sensor Sofa', 'TOOTHBRUSH',\n       'TV CONTROLLER', 'TV Sensor', 'WARDROBE DOOR', 'WATER BOTTLE', 'X', 'Y',\n       'Z', 'floor_01,01', 'floor_01,02', 'floor_01,03', 'floor_01,04',\n       'floor_01,05', 'floor_01,06', 'floor_01,07', 'floor_01,08',\n       'floor_01,09', 'floor_02,01', 'floor_02,02', 'floor_02,03',\n       'floor_02,04', 'floor_02,05', 'floor_02,06', 'floor_02,07',\n       'floor_02,08', 'floor_02,09', 'floor_03,01', 'floor_03,02',\n       'floor_03,03', 'floor_03,04', 'floor_03,05', 'floor_03,06',\n       'floor_03,07', 'floor_03,08', 'floor_03,09', 'floor_04,01',\n       'floor_04,02', 'floor_04,03', 'floor_04,04', 'floor_04,05',\n       'floor_04,06', 'floor_04,07', 'floor_04,08', 'floor_04,09',\n       'floor_05,06', 'floor_05,07', 'activity', 'segment'],\n      dtype='object')\n<class 'pandas.core.frame.DataFrame'>\nIndex: 6326 entries, 0 to 6325\nData columns (total 85 columns):\nTIMESTAMP                  6326 non-null datetime64[ns]\nBATHROOM TAP               6326 non-null float64\nBED                        6326 non-null float64\nBOOK                       6326 non-null float64\nMedication Box Sensor      6326 non-null float64\nFruit Platter Sensor       6326 non-null float64\nPots Sensor                6326 non-null float64\nWater Bottle Sensor        6326 non-null float64\nTrash Sensor               6326 non-null float64\nTap Sensor                 6326 non-null float64\nTank Sensor                6326 non-null float64\nPyjamas drawer Sensor      6326 non-null float64\nBed Sensor                 6326 non-null float64\nRefrigerator Sensor        6326 non-null float64\nMicrowave  Sensor          6326 non-null float64\nWardrobe Sensor            6326 non-null float64\nCupboard Cups Sensor       6326 non-null float64\nDishwasher Sensor          6326 non-null float64\nTop WC Sensor              6326 non-null float64\nCloset Sensor              6326 non-null float64\nWashing Machine  Sensor    6326 non-null float64\nPantry Sensor              6326 non-null float64\nENTRANCE DOOR              6326 non-null float64\nFOOD CUPBOARD              6326 non-null float64\nFRIDGE                     6326 non-null float64\nGARBAGE CAN                6326 non-null float64\nKettle Sensor              6326 non-null float64\nLAUNDRY BASKET             6326 non-null float64\nDoor Sensor                6326 non-null float64\nMEDICINE BOX               6326 non-null float64\nPOT DRAWER                 6326 non-null float64\nPYJAMAS DRAWER             6326 non-null float64\nSofa Pressure Sensor       6326 non-null float64\nMotion Sensor Kitchen      6326 non-null float64\nMotion Sensor Bathroom     6326 non-null float64\nMotion Sensor Bedroom      6326 non-null float64\nMotion Sensor Sofa         6326 non-null float64\nTOOTHBRUSH                 6326 non-null float64\nTV CONTROLLER              6326 non-null float64\nTV Sensor                  6326 non-null float64\nWARDROBE DOOR              6326 non-null float64\nWATER BOTTLE               6326 non-null float64\nX                          6326 non-null float64\nY                          6326 non-null float64\nZ                          6326 non-null float64\nfloor_01,01                6326 non-null float64\nfloor_01,02                6326 non-null float64\nfloor_01,03                6326 non-null float64\nfloor_01,04                6326 non-null float64\nfloor_01,05                6326 non-null float64\nfloor_01,06                6326 non-null float64\nfloor_01,07                6326 non-null float64\nfloor_01,08                6326 non-null float64\nfloor_01,09                6326 non-null float64\nfloor_02,01                6326 non-null float64\nfloor_02,02                6326 non-null float64\nfloor_02,03                6326 non-null float64\nfloor_02,04                6326 non-null float64\nfloor_02,05                6326 non-null float64\nfloor_02,06                6326 non-null float64\nfloor_02,07                6326 non-null float64\nfloor_02,08                6326 non-null float64\nfloor_02,09                6326 non-null float64\nfloor_03,01                6326 non-null float64\nfloor_03,02                6326 non-null float64\nfloor_03,03                6326 non-null float64\nfloor_03,04                6326 non-null float64\nfloor_03,05                6326 non-null float64\nfloor_03,06                6326 non-null float64\nfloor_03,07                6326 non-null float64\nfloor_03,08                6326 non-null float64\nfloor_03,09                6326 non-null float64\nfloor_04,01                6326 non-null float64\nfloor_04,02                6326 non-null float64\nfloor_04,03                6326 non-null float64\nfloor_04,04                6326 non-null float64\nfloor_04,05                6326 non-null float64\nfloor_04,06                6326 non-null float64\nfloor_04,07                6326 non-null float64\nfloor_04,08                6326 non-null float64\nfloor_04,09                6326 non-null float64\nfloor_05,06                6326 non-null float64\nfloor_05,07                6326 non-null float64\nactivity                   6326 non-null float64\nsegment                    6326 non-null float64\ndtypes: datetime64[ns](1), float64(84)\nmemory usage: 4.2+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# map strings to numbers\n",
    "\n",
    "\n",
    "\n",
    "sensors_map = {\"M01\": \"Door Sensor\", \"TV0\": \"TV Sensor\", \"SM1\": \"Motion Sensor Kitchen\", \"SM3\": \"Motion Sensor Bathroom\", \n",
    "               \"SM4\": \"Motion Sensor Bedroom\", \"C01\": \"Medication Box Sensor\", \"SM5\": \"Motion Sensor Sofa\", \"D01\": \"Refrigerator Sensor\", \n",
    "               \"D02\": \"Microwave  Sensor\", \"D03\": \"Wardrobe Sensor\", \"D04\": \"Cupboard Cups Sensor\", \"D05\": \"Dishwasher Sensor\", \"D07\": \"Top WC Sensor\", \n",
    "               \"D08\": \"Closet Sensor\", \"D09\": \"Washing Machine  Sensor\", \"D10\": \"Pantry Sensor\", \"H01\": \"Kettle Sensor\", \"C02\": \"Fruit Platter Sensor\", \n",
    "               \"C03\": \"Cutlery Sensor\", \"C04\": \"Pots Sensor\", \"C05\": \"Water Bottle Sensor\", \"C07\": \"Remote XBOX Sensor\", \"C08\": \"Trash Sensor\", \n",
    "               \"C09\": \"Tap Sensor\", \"C10\": \"Tank Sensor\", \"C12\": \"Laundry Basket Sensor\", \"C13\": \"Pyjamas drawer Sensor\", \"C14\": \"Bed Sensor\",\n",
    "               \"C015\": \"Contact Sensor Kitchen Faucet\", \"S09\": \"Sofa Pressure Sensor\"}\n",
    "\n",
    "samples_training = samples_training.rename(index=str, columns=sensors_map)\n",
    "\n",
    "\n",
    "# drop useless proximity features\n",
    "samples_training = samples_training.drop([\"Contact Sensor Kitchen Faucet\"], axis=1)\n",
    "samples_training = samples_training.drop([\"Remote XBOX Sensor\"], axis=1)\n",
    "samples_training = samples_training.drop([\"Cutlery Sensor\"], axis=1)\n",
    "samples_training = samples_training.drop([\"Laundry Basket Sensor\"], axis=1)\n",
    "\n",
    "# drop errors from floor data\n",
    "samples_training = samples_training.drop([\"floor_01,0A\"], axis=1)\n",
    "\n",
    "print(samples_training.head())\n",
    "print(samples_training.columns)\n",
    "print(samples_training.info())\n",
    "\n",
    "\n",
    "\n",
    "y = samples_training[\"activity\"]\n",
    "samples_training = samples_training.drop([\"activity\"], axis=1)\n",
    "samples_training[\"activity\"] = y.astype(int)\n",
    "\n",
    "# store data into CSV\n",
    "samples_training.to_csv(\"./src/samples-training.csv\", sep=';', encoding='utf-8', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
